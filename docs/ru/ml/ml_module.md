# ML –º–æ–¥—É–ª—å DataCode

–ú–æ–¥—É–ª—å `ml` –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –ø–æ–ª–Ω—ã–π –Ω–∞–±–æ—Ä —Ñ—É–Ω–∫—Ü–∏–π –¥–ª—è –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –≤ DataCode, –≤–∫–ª—é—á–∞—è —Ä–∞–±–æ—Ç—É —Å —Ç–µ–Ω–∑–æ—Ä–∞–º–∏, —Å–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π, –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –∏ —Ä–∞–±–æ—Ç—É —Å –¥–∞–Ω–Ω—ã–º–∏.

**üìö –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:**
- –ë–∞–∑–æ–≤—ã–µ –ø—Ä–∏–º–µ—Ä—ã: [`examples/ru/11-mnist-mlp/`](../../examples/ru/11-mnist-mlp/)
- –ü—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è: [–°—Ö–µ–º–∞ –æ–±—É—á–µ–Ω–∏—è –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏](./training_flow.md)
- –§–æ—Ä–º–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π: [–§–æ—Ä–º–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π](./model_save_format.md)

## –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

1. [–í–≤–µ–¥–µ–Ω–∏–µ](#–≤–≤–µ–¥–µ–Ω–∏–µ)
2. [Tensor –æ–ø–µ—Ä–∞—Ü–∏–∏](#tensor-–æ–ø–µ—Ä–∞—Ü–∏–∏)
3. [Graph –æ–ø–µ—Ä–∞—Ü–∏–∏](#graph-–æ–ø–µ—Ä–∞—Ü–∏–∏)
4. [Linear Regression](#linear-regression)
5. [Optimizers](#optimizers)
6. [Loss —Ñ—É–Ω–∫—Ü–∏–∏](#loss-—Ñ—É–Ω–∫—Ü–∏–∏)
7. [Dataset —Ñ—É–Ω–∫—Ü–∏–∏](#dataset-—Ñ—É–Ω–∫—Ü–∏–∏)
8. [Layer —Ñ—É–Ω–∫—Ü–∏–∏](#layer-—Ñ—É–Ω–∫—Ü–∏–∏)
9. [Neural Network —Ñ—É–Ω–∫—Ü–∏–∏](#neural-network-—Ñ—É–Ω–∫—Ü–∏–∏)
10. [–ú–µ—Ç–æ–¥—ã –æ–±—ä–µ–∫—Ç–æ–≤](#–º–µ—Ç–æ–¥—ã-–æ–±—ä–µ–∫—Ç–æ–≤)
11. [–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è](#–ø—Ä–∏–º–µ—Ä—ã-–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è)

---

## –í–≤–µ–¥–µ–Ω–∏–µ

–ú–æ–¥—É–ª—å `ml` –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç—Å—è –≤ –Ω–∞—á–∞–ª–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã:

```datacode
import ml
```

–ü–æ—Å–ª–µ –∏–º–ø–æ—Ä—Ç–∞ –¥–æ—Å—Ç—É–ø–Ω—ã –≤—Å–µ —Ñ—É–Ω–∫—Ü–∏–∏ –º–æ–¥—É–ª—è —á–µ—Ä–µ–∑ –ø—Ä–µ—Ñ–∏–∫—Å `ml.`, –Ω–∞–ø—Ä–∏–º–µ—Ä:
- `ml.tensor()` - —Å–æ–∑–¥–∞–Ω–∏–µ —Ç–µ–Ω–∑–æ—Ä–∞
- `ml.neural_network()` - —Å–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏
- `ml.layer.linear()` - —Å–æ–∑–¥–∞–Ω–∏–µ –ª–∏–Ω–µ–π–Ω–æ–≥–æ —Å–ª–æ—è

–ú–æ–¥—É–ª—å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–∞–±–æ—Ç—É –Ω–∞ CPU –∏ GPU (Metal –¥–ª—è macOS, CUDA –¥–ª—è Linux/Windows).

---

## Tensor –æ–ø–µ—Ä–∞—Ü–∏–∏

### `ml.tensor(data, shape?)`

–°–æ–∑–¥–∞–µ—Ç —Ç–µ–Ω–∑–æ—Ä –∏–∑ –¥–∞–Ω–Ω—ã—Ö. –§–æ—Ä–º–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `data` (array | number) - –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–µ–Ω–∑–æ—Ä–∞ (–º–∞—Å—Å–∏–≤ —á–∏—Å–µ–ª –∏–ª–∏ –≤–ª–æ–∂–µ–Ω–Ω—ã–µ –º–∞—Å—Å–∏–≤—ã)
- `shape` (array, –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) - —è–≤–Ω–∞—è —Ñ–æ—Ä–º–∞ —Ç–µ–Ω–∑–æ—Ä–∞ `[dim1, dim2, ...]`

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `tensor` - –æ–±—ä–µ–∫—Ç —Ç–µ–Ω–∑–æ—Ä–∞

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ–æ—Ä–º—ã
t1 = ml.tensor([1.0, 2.0, 3.0])  # –§–æ—Ä–º–∞: [3]
t2 = ml.tensor([[1, 2], [3, 4]])  # –§–æ—Ä–º–∞: [2, 2]

# –Ø–≤–Ω–æ–µ —É–∫–∞–∑–∞–Ω–∏–µ —Ñ–æ—Ä–º—ã
t3 = ml.tensor([1.0, 2.0, 3.0, 4.0], [2, 2])  # –§–æ—Ä–º–∞: [2, 2]
```

---

### `ml.shape(tensor)`

–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ñ–æ—Ä–º—É —Ç–µ–Ω–∑–æ—Ä–∞.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `tensor` (tensor) - —Ç–µ–Ω–∑–æ—Ä

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `array` - –º–∞—Å—Å–∏–≤ —Ä–∞–∑–º–µ—Ä–æ–≤ –ø–æ –∫–∞–∂–¥–æ–º—É –∏–∑–º–µ—Ä–µ–Ω–∏—é

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
t = ml.tensor([[1, 2], [3, 4]])
shape = ml.shape(t)  # [2, 2]
```

---

### `ml.data(tensor)`

–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Ç–µ–Ω–∑–æ—Ä–∞ –∫–∞–∫ –ø–ª–æ—Å–∫–∏–π –º–∞—Å—Å–∏–≤.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `tensor` (tensor) - —Ç–µ–Ω–∑–æ—Ä

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `array` - –º–∞—Å—Å–∏–≤ —á–∏—Å–µ–ª

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
t = ml.tensor([[1, 2], [3, 4]])
data = ml.data(t)  # [1.0, 2.0, 3.0, 4.0]
```

---

### `ml.add(t1, t2)`

–ü–æ—ç–ª–µ–º–µ–Ω—Ç–Ω–æ–µ —Å–ª–æ–∂–µ–Ω–∏–µ –¥–≤—É—Ö —Ç–µ–Ω–∑–æ—Ä–æ–≤.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `t1` (tensor) - –ø–µ—Ä–≤—ã–π —Ç–µ–Ω–∑–æ—Ä
- `t2` (tensor) - –≤—Ç–æ—Ä–æ–π —Ç–µ–Ω–∑–æ—Ä

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `tensor` - —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–ª–æ–∂–µ–Ω–∏—è

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
t1 = ml.tensor([1, 2, 3])
t2 = ml.tensor([4, 5, 6])
result = ml.add(t1, t2)  # [5, 7, 9]
```

---

### `ml.sub(t1, t2)`

–ü–æ—ç–ª–µ–º–µ–Ω—Ç–Ω–æ–µ –≤—ã—á–∏—Ç–∞–Ω–∏–µ –¥–≤—É—Ö —Ç–µ–Ω–∑–æ—Ä–æ–≤.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `t1` (tensor) - –ø–µ—Ä–≤—ã–π —Ç–µ–Ω–∑–æ—Ä
- `t2` (tensor) - –≤—Ç–æ—Ä–æ–π —Ç–µ–Ω–∑–æ—Ä

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `tensor` - —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã—á–∏—Ç–∞–Ω–∏—è

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
t1 = ml.tensor([5, 7, 9])
t2 = ml.tensor([1, 2, 3])
result = ml.sub(t1, t2)  # [4, 5, 6]
```

---

### `ml.mul(t1, t2)`

–ü–æ—ç–ª–µ–º–µ–Ω—Ç–Ω–æ–µ —É–º–Ω–æ–∂–µ–Ω–∏–µ –¥–≤—É—Ö —Ç–µ–Ω–∑–æ—Ä–æ–≤.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `t1` (tensor) - –ø–µ—Ä–≤—ã–π —Ç–µ–Ω–∑–æ—Ä
- `t2` (tensor) - –≤—Ç–æ—Ä–æ–π —Ç–µ–Ω–∑–æ—Ä

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `tensor` - —Ä–µ–∑—É–ª—å—Ç–∞—Ç —É–º–Ω–æ–∂–µ–Ω–∏—è

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
t1 = ml.tensor([2, 3, 4])
t2 = ml.tensor([5, 6, 7])
result = ml.mul(t1, t2)  # [10, 18, 28]
```

---

### `ml.matmul(t1, t2)`

–ú–∞—Ç—Ä–∏—á–Ω–æ–µ —É–º–Ω–æ–∂–µ–Ω–∏–µ –¥–≤—É—Ö —Ç–µ–Ω–∑–æ—Ä–æ–≤.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `t1` (tensor) - –ø–µ—Ä–≤—ã–π —Ç–µ–Ω–∑–æ—Ä (—Ñ–æ—Ä–º–∞ `[n, m]`)
- `t2` (tensor) - –≤—Ç–æ—Ä–æ–π —Ç–µ–Ω–∑–æ—Ä (—Ñ–æ—Ä–º–∞ `[m, k]`)

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `tensor` - —Ä–µ–∑—É–ª—å—Ç–∞—Ç –º–∞—Ç—Ä–∏—á–Ω–æ–≥–æ —É–º–Ω–æ–∂–µ–Ω–∏—è (—Ñ–æ—Ä–º–∞ `[n, k]`)

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
t1 = ml.tensor([[1, 2], [3, 4]])  # [2, 2]
t2 = ml.tensor([[5, 6], [7, 8]])  # [2, 2]
result = ml.matmul(t1, t2)  # [[19, 22], [43, 50]]
```

---

### `ml.transpose(tensor)`

–¢—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–Ω–∑–æ—Ä–∞.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `tensor` (tensor) - —Ç–µ–Ω–∑–æ—Ä (—Ñ–æ—Ä–º–∞ `[n, m]`)

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `tensor` - —Ç—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–Ω–∑–æ—Ä (—Ñ–æ—Ä–º–∞ `[m, n]`)

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
t = ml.tensor([[1, 2, 3], [4, 5, 6]])  # [2, 3]
result = ml.transpose(t)  # [[1, 4], [2, 5], [3, 6]] - —Ñ–æ—Ä–º–∞ [3, 2]
```

---

### `ml.sum(tensor)`

–°—É–º–º–∞ –≤—Å–µ—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Ç–µ–Ω–∑–æ—Ä–∞.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `tensor` (tensor) - —Ç–µ–Ω–∑–æ—Ä

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `number` - —Å—É–º–º–∞ –≤—Å–µ—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
t = ml.tensor([[1, 2], [3, 4]])
s = ml.sum(t)  # 10.0
```

---

### `ml.mean(tensor)`

–°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤—Å–µ—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Ç–µ–Ω–∑–æ—Ä–∞.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `tensor` (tensor) - —Ç–µ–Ω–∑–æ—Ä

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `number` - —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
t = ml.tensor([[1, 2], [3, 4]])
m = ml.mean(t)  # 2.5
```

---

### `ml.max_idx(tensor)`

–ù–∞—Ö–æ–¥–∏—Ç –∏–Ω–¥–µ–∫—Å—ã –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤. –î–ª—è 1D —Ç–µ–Ω–∑–æ—Ä–æ–≤ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–¥–∏–Ω –∏–Ω–¥–µ–∫—Å, –¥–ª—è –º–Ω–æ–≥–æ–º–µ—Ä–Ω—ã—Ö - –º–∞—Å—Å–∏–≤ –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å—Ä–µ–∑–∞ –ø–æ –ø–µ—Ä–≤–æ–º—É –∏–∑–º–µ—Ä–µ–Ω–∏—é.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `tensor` (tensor) - —Ç–µ–Ω–∑–æ—Ä

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `array` - –º–∞—Å—Å–∏–≤ –∏–Ω–¥–µ–∫—Å–æ–≤

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
t = ml.tensor([3, 1, 4, 1, 5])
idx = ml.max_idx(t)  # [4] - –∏–Ω–¥–µ–∫—Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞
```

---

### `ml.min_idx(tensor)`

–ù–∞—Ö–æ–¥–∏—Ç –∏–Ω–¥–µ–∫—Å—ã –º–∏–Ω–∏–º–∞–ª—å–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤. –î–ª—è 1D —Ç–µ–Ω–∑–æ—Ä–æ–≤ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–¥–∏–Ω –∏–Ω–¥–µ–∫—Å, –¥–ª—è –º–Ω–æ–≥–æ–º–µ—Ä–Ω—ã—Ö - –º–∞—Å—Å–∏–≤ –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å—Ä–µ–∑–∞ –ø–æ –ø–µ—Ä–≤–æ–º—É –∏–∑–º–µ—Ä–µ–Ω–∏—é.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `tensor` (tensor) - —Ç–µ–Ω–∑–æ—Ä

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `array` - –º–∞—Å—Å–∏–≤ –∏–Ω–¥–µ–∫—Å–æ–≤

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
t = ml.tensor([3, 1, 4, 1, 5])
idx = ml.min_idx(t)  # [1] –∏–ª–∏ [3] - –∏–Ω–¥–µ–∫—Å –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞
```

---

## Graph –æ–ø–µ—Ä–∞—Ü–∏–∏

–ì—Ä–∞—Ñ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏—è (autograd).

### `ml.graph()`

–°–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—ã–π –≥—Ä–∞—Ñ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:** –Ω–µ—Ç

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `graph` - –æ–±—ä–µ–∫—Ç –≥—Ä–∞—Ñ–∞

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
g = ml.graph()
```

---

### `ml.graph_add_input(graph)`

–î–æ–±–∞–≤–ª—è–µ—Ç –≤—Ö–æ–¥–Ω–æ–π —É–∑–µ–ª –≤ –≥—Ä–∞—Ñ.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `graph` (graph) - –≥—Ä–∞—Ñ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `number` - ID —É–∑–ª–∞

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
g = ml.graph()
input_id = ml.graph_add_input(g)
```

---

### `ml.graph_add_op(graph, op_name, input_node_ids)`

–î–æ–±–∞–≤–ª—è–µ—Ç –æ–ø–µ—Ä–∞—Ü–∏—é –≤ –≥—Ä–∞—Ñ.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `graph` (graph) - –≥—Ä–∞—Ñ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
- `op_name` (string) - –∏–º—è –æ–ø–µ—Ä–∞—Ü–∏–∏: `"add"`, `"sub"`, `"mul"`, `"matmul"`, `"transpose"`, `"sum"`, `"mean"`
- `input_node_ids` (array) - –º–∞—Å—Å–∏–≤ ID –≤—Ö–æ–¥–Ω—ã—Ö —É–∑–ª–æ–≤

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `number` - ID –Ω–æ–≤–æ–≥–æ —É–∑–ª–∞

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
g = ml.graph()
input1 = ml.graph_add_input(g)
input2 = ml.graph_add_input(g)
add_node = ml.graph_add_op(g, "add", [input1, input2])
```

---

### `ml.graph_forward(graph, input_tensors)`

–í—ã–ø–æ–ª–Ω—è–µ—Ç –ø—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ –≥—Ä–∞—Ñ.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `graph` (graph) - –≥—Ä–∞—Ñ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
- `input_tensors` (array) - –º–∞—Å—Å–∏–≤ –≤—Ö–æ–¥–Ω—ã—Ö —Ç–µ–Ω–∑–æ—Ä–æ–≤

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `null`

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
g = ml.graph()
input_id = ml.graph_add_input(g)
t1 = ml.tensor([1, 2, 3])
ml.graph_forward(g, [t1])
```

---

### `ml.graph_get_output(graph, node_id)`

–ü–æ–ª—É—á–∞–µ—Ç –≤—ã—Ö–æ–¥–Ω–æ–π —Ç–µ–Ω–∑–æ—Ä —É–∑–ª–∞ –ø–æ—Å–ª–µ –ø—Ä—è–º–æ–≥–æ –ø—Ä–æ—Ö–æ–¥–∞.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `graph` (graph) - –≥—Ä–∞—Ñ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
- `node_id` (number) - ID —É–∑–ª–∞

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `tensor` - –≤—ã—Ö–æ–¥–Ω–æ–π —Ç–µ–Ω–∑–æ—Ä

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
output = ml.graph_get_output(g, node_id)
```

---

### `ml.graph_backward(graph, output_node_id)`

–í—ã–ø–æ–ª–Ω—è–µ—Ç –æ–±—Ä–∞—Ç–Ω—ã–π –ø—Ä–æ—Ö–æ–¥ (backpropagation) –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `graph` (graph) - –≥—Ä–∞—Ñ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
- `output_node_id` (number) - ID –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —É–∑–ª–∞

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `null`

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
ml.graph_backward(g, output_node_id)
```

---

### `ml.graph_get_gradient(graph, node_id)`

–ü–æ–ª—É—á–∞–µ—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç —É–∑–ª–∞ –ø–æ—Å–ª–µ –æ–±—Ä–∞—Ç–Ω–æ–≥–æ –ø—Ä–æ—Ö–æ–¥–∞.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `graph` (graph) - –≥—Ä–∞—Ñ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
- `node_id` (number) - ID —É–∑–ª–∞

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `tensor` - –≥—Ä–∞–¥–∏–µ–Ω—Ç

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
grad = ml.graph_get_gradient(g, node_id)
```

---

### `ml.graph_zero_grad(graph)`

–û–±–Ω—É–ª—è–µ—Ç –≤—Å–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –≤ –≥—Ä–∞—Ñ–µ.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `graph` (graph) - –≥—Ä–∞—Ñ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `null`

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
ml.graph_zero_grad(g)
```

---

### `ml.graph_set_requires_grad(graph, node_id, requires_grad)`

–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç, —Ç—Ä–µ–±—É–µ—Ç—Å—è –ª–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞ –¥–ª—è —É–∑–ª–∞.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `graph` (graph) - –≥—Ä–∞—Ñ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
- `node_id` (number) - ID —É–∑–ª–∞
- `requires_grad` (bool) - —Ç—Ä–µ–±—É–µ—Ç—Å—è –ª–∏ –≥—Ä–∞–¥–∏–µ–Ω—Ç

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `null`

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
ml.graph_set_requires_grad(g, node_id, true)
```

---

## Linear Regression

### `ml.linear_regression(feature_count)`

–°–æ–∑–¥–∞–µ—Ç –º–æ–¥–µ–ª—å –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `feature_count` (number) - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `linear_regression` - –æ–±—ä–µ–∫—Ç –º–æ–¥–µ–ª–∏

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
model = ml.linear_regression(3)  # 3 –ø—Ä–∏–∑–Ω–∞–∫–∞
```

---

### `ml.lr_predict(model, features)`

–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `model` (linear_regression) - –º–æ–¥–µ–ª—å
- `features` (tensor) - –ø—Ä–∏–∑–Ω–∞–∫–∏ (—Ñ–æ—Ä–º–∞ `[batch_size, feature_count]`)

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `tensor` - –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (—Ñ–æ—Ä–º–∞ `[batch_size, 1]`)

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
x = ml.tensor([[1, 2, 3], [4, 5, 6]])  # [2, 3]
predictions = ml.lr_predict(model, x)
```

---

### `ml.lr_train(model, x, y, epochs, lr)`

–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `model` (linear_regression) - –º–æ–¥–µ–ª—å
- `x` (tensor) - –ø—Ä–∏–∑–Ω–∞–∫–∏ (—Ñ–æ—Ä–º–∞ `[batch_size, feature_count]`)
- `y` (tensor) - —Ü–µ–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (—Ñ–æ—Ä–º–∞ `[batch_size, 1]`)
- `epochs` (number) - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö
- `lr` (number) - —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `array` - –∏—Å—Ç–æ—Ä–∏—è –ø–æ—Ç–µ—Ä—å

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
loss_history = ml.lr_train(model, x_train, y_train, 100, 0.01)
```

---

### `ml.lr_evaluate(model, x, y)`

–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ (–≤—ã—á–∏—Å–ª—è–µ—Ç MSE).

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `model` (linear_regression) - –º–æ–¥–µ–ª—å
- `x` (tensor) - –ø—Ä–∏–∑–Ω–∞–∫–∏
- `y` (tensor) - —Ü–µ–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `number` - MSE (Mean Squared Error)

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
mse = ml.lr_evaluate(model, x_test, y_test)
```

---

## Optimizers

### `ml.sgd(learning_rate)`

–°–æ–∑–¥–∞–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä SGD (Stochastic Gradient Descent).

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `learning_rate` (number) - —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `sgd` - –æ–±—ä–µ–∫—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
optimizer = ml.sgd(0.001)
```

---

### `ml.sgd_step(optimizer, graph, param_node_ids)`

–í—ã–ø–æ–ª–Ω—è–µ—Ç –æ–¥–∏–Ω —à–∞–≥ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ SGD.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `optimizer` (sgd) - –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
- `graph` (graph) - –≥—Ä–∞—Ñ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
- `param_node_ids` (array) - –º–∞—Å—Å–∏–≤ ID —É–∑–ª–æ–≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `null`

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
ml.sgd_step(optimizer, graph, [weight_id, bias_id])
```

---

### `ml.sgd_zero_grad(graph)`

–û–±–Ω—É–ª—è–µ—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –≤ –≥—Ä–∞—Ñ–µ (—É–¥–æ–±–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è SGD).

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `graph` (graph) - –≥—Ä–∞—Ñ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `null`

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
ml.sgd_zero_grad(graph)
```

---

### `ml.adam(learning_rate, beta1?, beta2?, epsilon?)`

–°–æ–∑–¥–∞–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä Adam.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `learning_rate` (number) - —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è
- `beta1` (number, –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) - –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ –º–æ–º–µ–Ω—Ç–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.9)
- `beta2` (number, –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) - –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–ª—è –≤—Ç–æ—Ä–æ–≥–æ –º–æ–º–µ–Ω—Ç–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.999)
- `epsilon` (number, –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) - –º–∞–ª–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è —á–∏—Å–ª–µ–Ω–Ω–æ–π —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1e-8)

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `adam` - –æ–±—ä–µ–∫—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
optimizer = ml.adam(0.001)  # –° –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
optimizer2 = ml.adam(0.001, 0.9, 0.999, 1e-8)  # –° —è–≤–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
```

---

### `ml.adam_step(optimizer, graph, param_node_ids)`

–í—ã–ø–æ–ª–Ω—è–µ—Ç –æ–¥–∏–Ω —à–∞–≥ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ Adam.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `optimizer` (adam) - –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
- `graph` (graph) - –≥—Ä–∞—Ñ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
- `param_node_ids` (array) - –º–∞—Å—Å–∏–≤ ID —É–∑–ª–æ–≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `null`

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
ml.adam_step(optimizer, graph, [weight_id, bias_id])
```

---

## Loss —Ñ—É–Ω–∫—Ü–∏–∏

### `ml.mse_loss(y_pred, y_true)`

–í—ã—á–∏—Å–ª—è–µ—Ç Mean Squared Error (—Å—Ä–µ–¥–Ω–µ–∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω—É—é –æ—à–∏–±–∫—É).

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `y_pred` (tensor) - –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
- `y_true` (tensor) - –∏—Å—Ç–∏–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `tensor` - —Ç–µ–Ω–∑–æ—Ä –ø–æ—Ç–µ—Ä—å

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
loss = ml.mse_loss(predictions, targets)
```

---

### `ml.cross_entropy_loss(logits, class_indices)`

**–£–°–¢–ê–†–ï–õ–û**: –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `sparse_softmax_cross_entropy_loss` –∏–ª–∏ `categorical_cross_entropy_loss`.

---

### `ml.binary_cross_entropy_loss(y_pred, y_true)`

–í—ã—á–∏—Å–ª—è–µ—Ç Binary Cross Entropy Loss (–¥–ª—è –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏).

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `y_pred` (tensor) - –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ (—Ñ–æ—Ä–º–∞ `[batch_size, 1]`)
- `y_true` (tensor) - –∏—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ (—Ñ–æ—Ä–º–∞ `[batch_size, 1]`, –∑–Ω–∞—á–µ–Ω–∏—è 0 –∏–ª–∏ 1)

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `tensor` - —Ç–µ–Ω–∑–æ—Ä –ø–æ—Ç–µ—Ä—å

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
loss = ml.binary_cross_entropy_loss(predictions, targets)
```

---

### `ml.mae_loss(y_pred, y_true)`

–í—ã—á–∏—Å–ª—è–µ—Ç Mean Absolute Error (—Å—Ä–µ–¥–Ω—é—é –∞–±—Å–æ–ª—é—Ç–Ω—É—é –æ—à–∏–±–∫—É).

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `y_pred` (tensor) - –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
- `y_true` (tensor) - –∏—Å—Ç–∏–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `tensor` - —Ç–µ–Ω–∑–æ—Ä –ø–æ—Ç–µ—Ä—å

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
loss = ml.mae_loss(predictions, targets)
```

---

### `ml.huber_loss(y_pred, y_true, delta?)`

–í—ã—á–∏—Å–ª—è–µ—Ç Huber Loss (–∫–æ–º–±–∏–Ω–∞—Ü–∏—è MSE –∏ MAE).

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `y_pred` (tensor) - –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
- `y_true` (tensor) - –∏—Å—Ç–∏–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
- `delta` (number, –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) - –ø–æ—Ä–æ–≥–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1.0)

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `tensor` - —Ç–µ–Ω–∑–æ—Ä –ø–æ—Ç–µ—Ä—å

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
loss = ml.huber_loss(predictions, targets, 1.0)
```

---

### `ml.hinge_loss(y_pred, y_true)`

–í—ã—á–∏—Å–ª—è–µ—Ç Hinge Loss (–¥–ª—è SVM).

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `y_pred` (tensor) - –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
- `y_true` (tensor) - –∏—Å—Ç–∏–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (–æ–±—ã—á–Ω–æ -1 –∏–ª–∏ 1)

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `tensor` - —Ç–µ–Ω–∑–æ—Ä –ø–æ—Ç–µ—Ä—å

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
loss = ml.hinge_loss(predictions, targets)
```

---

### `ml.kl_divergence(y_pred, y_true)`

–í—ã—á–∏—Å–ª—è–µ—Ç Kullback-Leibler Divergence.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `y_pred` (tensor) - –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
- `y_true` (tensor) - –∏—Å—Ç–∏–Ω–Ω—ã–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `tensor` - —Ç–µ–Ω–∑–æ—Ä –ø–æ—Ç–µ—Ä—å

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
loss = ml.kl_divergence(predictions, targets)
```

---

### `ml.smooth_l1_loss(y_pred, y_true)`

–í—ã—á–∏—Å–ª—è–µ—Ç Smooth L1 Loss (–∫–æ–º–±–∏–Ω–∞—Ü–∏—è L1 –∏ L2).

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `y_pred` (tensor) - –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
- `y_true` (tensor) - –∏—Å—Ç–∏–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `tensor` - —Ç–µ–Ω–∑–æ—Ä –ø–æ—Ç–µ—Ä—å

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
loss = ml.smooth_l1_loss(predictions, targets)
```

---

### `ml.categorical_cross_entropy_loss(logits, targets)`

–í—ã—á–∏—Å–ª—è–µ—Ç Categorical Cross Entropy Loss –¥–ª—è –º–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å one-hot –º–µ—Ç–∫–∞–º–∏.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `logits` (tensor) - –ª–æ–≥–∏—Ç—ã –º–æ–¥–µ–ª–∏ (—Ñ–æ—Ä–º–∞ `[batch_size, num_classes]`)
- `targets` (tensor) - one-hot –º–µ—Ç–∫–∏ (—Ñ–æ—Ä–º–∞ `[batch_size, num_classes]`)

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `tensor` - —Ç–µ–Ω–∑–æ—Ä –ø–æ—Ç–µ—Ä—å

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –º–µ—Ç–æ–∫ –≤ one-hot
y_onehot = ml.onehot(y_train, 10)
loss = ml.categorical_cross_entropy_loss(logits, y_onehot)
```

**–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:** –î–ª—è –º–µ—Ç–æ–∫ –≤ –≤–∏–¥–µ –∏–Ω–¥–µ–∫—Å–æ–≤ –∫–ª–∞—Å—Å–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `sparse_softmax_cross_entropy_loss` —á–µ—Ä–µ–∑ `model.train()` —Å `loss="cross_entropy"`.

---

## Dataset —Ñ—É–Ω–∫—Ü–∏–∏

### `ml.dataset(table, feature_columns, target_columns)`

–°–æ–∑–¥–∞–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç –∏–∑ —Ç–∞–±–ª–∏—Ü—ã.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `table` (table) - —Ç–∞–±–ª–∏—Ü–∞ –¥–∞–Ω–Ω—ã—Ö
- `feature_columns` (array) - –º–∞—Å—Å–∏–≤ –∏–º–µ–Ω –∫–æ–ª–æ–Ω–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
- `target_columns` (array) - –º–∞—Å—Å–∏–≤ –∏–º–µ–Ω –∫–æ–ª–æ–Ω–æ–∫ —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `dataset` - –æ–±—ä–µ–∫—Ç –¥–∞—Ç–∞—Å–µ—Ç–∞

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
ds = ml.dataset(data_table, ["feature1", "feature2"], ["target"])
```

---

### `ml.dataset_features(dataset)`

–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–Ω–∑–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `dataset` (dataset) - –¥–∞—Ç–∞—Å–µ—Ç

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `tensor` - —Ç–µ–Ω–∑–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (—Ñ–æ—Ä–º–∞ `[num_samples, num_features]`)

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
x = ml.dataset_features(dataset)
```

---

### `ml.dataset_targets(dataset)`

–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–Ω–∑–æ—Ä —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `dataset` (dataset) - –¥–∞—Ç–∞—Å–µ—Ç

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `tensor` - —Ç–µ–Ω–∑–æ—Ä —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö (—Ñ–æ—Ä–º–∞ `[num_samples, num_targets]`)

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
y = ml.dataset_targets(dataset)
```

---

### `ml.onehot(labels, num_classes?)`

–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–æ–≤ –≤ one-hot –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `labels` (tensor) - –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–æ–≤ (—Ñ–æ—Ä–º–∞ `[N]` –∏–ª–∏ `[N, 1]`)
- `num_classes` (number, –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤ (–µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–æ, –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –∫–∞–∫ `max(labels) + 1`)

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `tensor` - one-hot —Ç–µ–Ω–∑–æ—Ä (—Ñ–æ—Ä–º–∞ `[N, num_classes]`)

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
labels = ml.tensor([[0], [1], [2], [0]])  # [4, 1]
y_onehot = ml.onehot(labels, 3)  # [4, 3]
# –†–µ–∑—É–ª—å—Ç–∞—Ç: [[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0]]
```

---

### `ml.load_mnist(split)`

–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç MNIST.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `split` (string) - —Ä–∞–∑–¥–µ–ª –¥–∞—Ç–∞—Å–µ—Ç–∞: `"train"` –∏–ª–∏ `"test"`

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `dataset` - –¥–∞—Ç–∞—Å–µ—Ç MNIST

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
train_dataset = ml.load_mnist("train")
test_dataset = ml.load_mnist("test")
```

**–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:** –§–∞–π–ª—ã MNIST –¥–æ–ª–∂–Ω—ã –Ω–∞—Ö–æ–¥–∏—Ç—å—Å—è –≤ `src/lib/ml/datasets/mnist/`.

---

## Layer —Ñ—É–Ω–∫—Ü–∏–∏

–°–ª–æ–∏ —Å–æ–∑–¥–∞—é—Ç—Å—è —á–µ—Ä–µ–∑ –ø–æ–¥–º–æ–¥—É–ª—å `ml.layer`:

### `ml.layer.linear(in_features, out_features)`

–°–æ–∑–¥–∞–µ—Ç –ª–∏–Ω–µ–π–Ω—ã–π (–ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π) —Å–ª–æ–π.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `in_features` (number) - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—Ö–æ–¥–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
- `out_features` (number) - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã—Ö–æ–¥–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `layer` - –æ–±—ä–µ–∫—Ç —Å–ª–æ—è

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
layer = ml.layer.linear(784, 128)  # 784 –≤—Ö–æ–¥–∞, 128 –≤—ã—Ö–æ–¥–æ–≤
```

---

### `ml.layer.relu()`

–°–æ–∑–¥–∞–µ—Ç —Å–ª–æ–π –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ ReLU.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:** –Ω–µ—Ç

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `layer` - –æ–±—ä–µ–∫—Ç —Å–ª–æ—è

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
relu_layer = ml.layer.relu()
```

---

### `ml.layer.softmax()`

–°–æ–∑–¥–∞–µ—Ç —Å–ª–æ–π –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ Softmax.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:** –Ω–µ—Ç

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `layer` - –æ–±—ä–µ–∫—Ç —Å–ª–æ—è

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
softmax_layer = ml.layer.softmax()
```

---

### `ml.layer.flatten()`

–°–æ–∑–¥–∞–µ—Ç —Å–ª–æ–π Flatten (–ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –º–Ω–æ–≥–æ–º–µ—Ä–Ω—ã–π —Ç–µ–Ω–∑–æ—Ä –≤ –æ–¥–Ω–æ–º–µ—Ä–Ω—ã–π).

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:** –Ω–µ—Ç

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `layer` - –æ–±—ä–µ–∫—Ç —Å–ª–æ—è

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
flatten_layer = ml.layer.flatten()
```

---

## Neural Network —Ñ—É–Ω–∫—Ü–∏–∏

### `ml.sequential(layers)`

–°–æ–∑–¥–∞–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä —Å–ª–æ–µ–≤.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `layers` (array) - –º–∞—Å—Å–∏–≤ —Å–ª–æ–µ–≤

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `sequential` - –æ–±—ä–µ–∫—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
layer1 = ml.layer.linear(784, 128)
layer2 = ml.layer.relu()
layer3 = ml.layer.linear(128, 10)
seq = ml.sequential([layer1, layer2, layer3])
```

---

### `ml.sequential_add(sequential, layer)`

–î–æ–±–∞–≤–ª—è–µ—Ç —Å–ª–æ–π –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `sequential` (sequential) - –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
- `layer` (layer) - —Å–ª–æ–π –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `null`

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
ml.sequential_add(seq, ml.layer.softmax())
```

---

### `ml.neural_network(sequential)`

–°–æ–∑–¥–∞–µ—Ç –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å –∏–∑ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `sequential` (sequential) - –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä —Å–ª–æ–µ–≤

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `neural_network` - –æ–±—ä–µ–∫—Ç –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
model = ml.neural_network(seq)
```

---

### `ml.nn_forward(model, x)`

–í—ã–ø–æ–ª–Ω—è–µ—Ç –ø—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `model` (neural_network | sequential | linear_regression) - –º–æ–¥–µ–ª—å
- `x` (tensor) - –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (—Ñ–æ—Ä–º–∞ `[batch_size, input_features]`)

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `tensor` - –≤—ã—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
output = ml.nn_forward(model, x)
```

---

### `ml.nn_train(model, x, y, epochs, batch_size, lr, loss_type, optimizer?, x_val?, y_val?)`

–û–±—É—á–∞–µ—Ç –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `model` (neural_network) - –º–æ–¥–µ–ª—å
- `x` (tensor) - –æ–±—É—á–∞—é—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (—Ñ–æ—Ä–º–∞ `[num_samples, num_features]`)
- `y` (tensor) - –æ–±—É—á–∞—é—â–∏–µ –º–µ—Ç–∫–∏ (—Ñ–æ—Ä–º–∞ `[num_samples, 1]` –¥–ª—è `cross_entropy` –∏–ª–∏ `[num_samples, num_classes]` –¥–ª—è `categorical_cross_entropy`)
- `epochs` (number) - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö
- `batch_size` (number) - —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
- `lr` (number) - —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è
- `loss_type` (string) - —Ç–∏–ø —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å: `"cross_entropy"`, `"categorical_cross_entropy"`, `"mse"`, `"binary_cross_entropy"`
- `optimizer` (string, –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) - –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä: `"SGD"`, `"Adam"`, `"Momentum"`, `"NAG"`, `"Adagrad"`, `"RMSprop"`, `"AdamW"` (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é `"SGD"`)
- `x_val` (tensor, –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) - –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
- `y_val` (tensor, –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) - –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `array` - –∏—Å—Ç–æ—Ä–∏—è –ø–æ—Ç–µ—Ä—å

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
# –ë–∞–∑–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ
loss_history = ml.nn_train(model, x_train, y_train, 10, 32, 0.001, "cross_entropy")

# –° –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–æ–º –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
loss_history = ml.nn_train(model, x_train, y_train, 10, 32, 0.001, 
                           "cross_entropy", "Adam", x_val, y_val)
```

---

### `ml.nn_train_sh(model, x, y, epochs, batch_size, lr, loss_type, optimizer, monitor, patience, min_delta, restore_best, x_val?, y_val?)`

–û–±—É—á–∞–µ—Ç –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å —Å early stopping –∏ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–æ–º —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `model` (neural_network) - –º–æ–¥–µ–ª—å
- `x` (tensor) - –æ–±—É—á–∞—é—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
- `y` (tensor) - –æ–±—É—á–∞—é—â–∏–µ –º–µ—Ç–∫–∏
- `epochs` (number) - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö
- `batch_size` (number) - —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
- `lr` (number) - –Ω–∞—á–∞–ª—å–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è
- `loss_type` (string) - —Ç–∏–ø —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å
- `optimizer` (string | null) - –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä (–∏–ª–∏ `null` –¥–ª—è SGD –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
- `monitor` (string) - –º–µ—Ç—Ä–∏–∫–∞ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞: `"loss"`, `"val_loss"`, `"acc"`, `"val_acc"`
- `patience` (number) - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –±–µ–∑ —É–ª—É—á—à–µ–Ω–∏—è –ø–µ—Ä–µ–¥ –æ—Å—Ç–∞–Ω–æ–≤–∫–æ–π
- `min_delta` (number) - –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è
- `restore_best` (bool) - –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—Ç—å –ª–∏ –ª—É—á—à–∏–µ –≤–µ—Å–∞ –ø–æ—Å–ª–µ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
- `x_val` (tensor, –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) - –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
- `y_val` (tensor, –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) - –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `object` - –æ–±—ä–µ–∫—Ç —Å –∏—Å—Ç–æ—Ä–∏–µ–π –æ–±—É—á–µ–Ω–∏—è:
- `loss` (array) - –∏—Å—Ç–æ—Ä–∏—è –ø–æ—Ç–µ—Ä—å –Ω–∞ –æ–±—É—á–µ–Ω–∏–∏
- `val_loss` (array | null) - –∏—Å—Ç–æ—Ä–∏—è –ø–æ—Ç–µ—Ä—å –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
- `acc` (array) - –∏—Å—Ç–æ—Ä–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏ –Ω–∞ –æ–±—É—á–µ–Ω–∏–∏
- `val_acc` (array | null) - –∏—Å—Ç–æ—Ä–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
- `lr` (array) - –∏—Å—Ç–æ—Ä–∏—è —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è
- `best_metric` (number) - –ª—É—á—à–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏
- `best_epoch` (number) - —ç–ø–æ—Ö–∞ —Å –ª—É—á—à–µ–π –º–µ—Ç—Ä–∏–∫–æ–π
- `stopped_epoch` (number) - —ç–ø–æ—Ö–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
history = ml.nn_train_sh(model, x_train, y_train, 50, 32, 0.001,
                         "cross_entropy", "Adam", "val_loss", 5, 0.0001, true,
                         x_val, y_val)
print("–õ—É—á—à–∞—è —ç–ø–æ—Ö–∞:", history.best_epoch)
print("–õ—É—á—à–∞—è –º–µ—Ç—Ä–∏–∫–∞:", history.best_metric)
```

---

### `ml.nn_save(model, path)`

–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å –≤ —Ñ–∞–π–ª.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `model` (neural_network) - –º–æ–¥–µ–ª—å
- `path` (path | string) - –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `null`

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
ml.nn_save(model, "model.nn")
ml.nn_save(model, path("models/my_model.nn"))
```

---

### `ml.nn_load(path)`

–ó–∞–≥—Ä—É–∂–∞–µ—Ç –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å –∏–∑ —Ñ–∞–π–ª–∞.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `path` (path | string) - –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `neural_network` - –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
model = ml.nn_load("model.nn")
model = ml.nn_load(path("models/my_model.nn"))
```

---

### `ml.save_model(model, path)`

–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–µ –∏–º—è –¥–ª—è `ml.nn_save()`.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `model` (neural_network) - –º–æ–¥–µ–ª—å
- `path` (path | string) - –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `null`

---

### `ml.load(path)`

–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–µ –∏–º—è –¥–ª—è `ml.nn_load()`.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `path` (path | string) - –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `neural_network` - –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å

---

### `ml.set_device(device_name)`

–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è ML –æ–ø–µ—Ä–∞—Ü–∏–π.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `device_name` (string) - –∏–º—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞: `"cpu"`, `"cuda"`, `"metal"`, `"auto"`

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `string` - –∏–º—è —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
ml.set_device("metal")  # macOS
ml.set_device("cuda")   # Linux/Windows —Å NVIDIA GPU
ml.set_device("cpu")    # CPU
```

**–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:** –ï—Å–ª–∏ GPU —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –æ—Ç–∫–∞—Ç –Ω–∞ CPU.

---

### `ml.get_device()`

–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â–µ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:** –Ω–µ—Ç

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `string` - –∏–º—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
device = ml.get_device()  # "cpu", "metal", "cuda"
```

---

### `ml.nn_set_device(model, device_name)`

–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `model` (neural_network) - –º–æ–¥–µ–ª—å
- `device_name` (string) - –∏–º—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `string` - –∏–º—è —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
model.device("metal")
```

---

### `ml.nn_get_device(model)`

–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `model` (neural_network) - –º–æ–¥–µ–ª—å

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `string` - –∏–º—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
device = ml.nn_get_device(model)
```

---

### `ml.validate_model(model)`

–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `model` (neural_network) - –º–æ–¥–µ–ª—å

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `bool` - `true` –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –≤–∞–ª–∏–¥–Ω–∞, `false` –∏–Ω–∞—á–µ

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
if ml.validate_model(model) {
    print("–ú–æ–¥–µ–ª—å –≤–∞–ª–∏–¥–Ω–∞")
}
```

---

### `ml.model_info(model, verbose?, format?, show_graph?)`

–í—ã–≤–æ–¥–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `model` (neural_network | linear_regression) - –º–æ–¥–µ–ª—å
- `verbose` (bool, –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) - –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –ª–∏ –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é `false`)
- `format` (string, –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) - —Ñ–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞: `"text"` –∏–ª–∏ `"json"` (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é `"text"`)
- `show_graph` (bool, –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) - –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –ª–∏ –≥—Ä–∞—Ñ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é `false`)

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `null` –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∞ `"text"`, `string` (JSON) –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∞ `"json"`

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
ml.model_info(model)  # –¢–µ–∫—Å—Ç–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
ml.model_info(model, true, "json")  # JSON —Ñ–æ—Ä–º–∞—Ç —Å –¥–µ—Ç–∞–ª—è–º–∏
```

---

### `ml.model_get_layer(model, index)`

–ü–æ–ª—É—á–∞–µ—Ç —Å–ª–æ–π –º–æ–¥–µ–ª–∏ –ø–æ –∏–Ω–¥–µ–∫—Å—É.

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `model` (neural_network) - –º–æ–¥–µ–ª—å
- `index` (number) - –∏–Ω–¥–µ–∫—Å —Å–ª–æ—è (–Ω–∞—á–∏–Ω–∞—è —Å 0)

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `layer` - –æ–±—ä–µ–∫—Ç —Å–ª–æ—è

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
first_layer = ml.model_get_layer(model, 0)
```

---

### `ml.layer_freeze(layer)`

–ó–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ—Ç —Å–ª–æ–π (–æ—Ç–∫–ª—é—á–∞–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏).

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `layer` (layer) - —Å–ª–æ–π

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `null`

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
ml.layer_freeze(first_layer)
```

---

### `ml.layer_unfreeze(layer)`

–†–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–µ—Ç —Å–ª–æ–π (–≤–∫–ª—é—á–∞–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏).

**–ê—Ä–≥—É–º–µ–Ω—Ç—ã:**
- `layer` (layer) - —Å–ª–æ–π

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:** `null`

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
ml.layer_unfreeze(first_layer)
```

---

## –ú–µ—Ç–æ–¥—ã –æ–±—ä–µ–∫—Ç–æ–≤

### Tensor

–¢–µ–Ω–∑–æ—Ä—ã –∏–º–µ—é—Ç —Å–ª–µ–¥—É—é—â–∏–µ —Å–≤–æ–π—Å—Ç–≤–∞ –∏ –º–µ—Ç–æ–¥—ã:

#### –°–≤–æ–π—Å—Ç–≤–∞

- **`tensor.shape`** - –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ñ–æ—Ä–º—É —Ç–µ–Ω–∑–æ—Ä–∞ –∫–∞–∫ –º–∞—Å—Å–∏–≤
- **`tensor.data`** - –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Ç–µ–Ω–∑–æ—Ä–∞ –∫–∞–∫ –ø–ª–æ—Å–∫–∏–π –º–∞—Å—Å–∏–≤

#### –ú–µ—Ç–æ–¥—ã

- **`tensor.max_idx()`** - –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω–¥–µ–∫—Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞
- **`tensor.min_idx()`** - –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω–¥–µ–∫—Å –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞

#### –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è

- **`tensor[i]`** - –¥–æ—Å—Ç—É–ø –∫ —ç–ª–µ–º–µ–Ω—Ç—É –ø–æ –∏–Ω–¥–µ–∫—Å—É:
  - –î–ª—è 1D —Ç–µ–Ω–∑–æ—Ä–æ–≤: –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–∫–∞–ª—è—Ä–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
  - –î–ª—è –º–Ω–æ–≥–æ–º–µ—Ä–Ω—ã—Ö —Ç–µ–Ω–∑–æ—Ä–æ–≤: –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ä–µ–∑ –ø–æ –ø–µ—Ä–≤–æ–º—É –∏–∑–º–µ—Ä–µ–Ω–∏—é

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
t = ml.tensor([[1, 2, 3], [4, 5, 6]])

# –°–≤–æ–π—Å—Ç–≤–∞
shape = t.shape  # [2, 3]
data = t.data    # [1.0, 2.0, 3.0, 4.0, 5.0, 6.0]

# –ú–µ—Ç–æ–¥—ã
max_idx = t.max_idx()  # [5] - –∏–Ω–¥–µ–∫—Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞
min_idx = t.min_idx()  # [0] - –∏–Ω–¥–µ–∫—Å –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞

# –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è
first_row = t[0]  # —Ç–µ–Ω–∑–æ—Ä [1, 2, 3]
second_row = t[1]  # —Ç–µ–Ω–∑–æ—Ä [4, 5, 6]
```

---

### NeuralNetwork

–ù–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ –∏–º–µ—é—Ç —Å–ª–µ–¥—É—é—â–∏–µ –º–µ—Ç–æ–¥—ã:

#### –ú–µ—Ç–æ–¥—ã

- **`model.train(x, y, epochs, batch_size, lr, loss_type, optimizer?, x_val?, y_val?)`** - –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
- **`model.train_sh(x, y, epochs, batch_size, lr, loss_type, optimizer, monitor, patience, min_delta, restore_best, x_val?, y_val?)`** - –æ–±—É—á–µ–Ω–∏–µ —Å early stopping
- **`model.save(path)`** - —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
- **`model.device(device_name)`** - —É—Å—Ç–∞–Ω–æ–≤–∫–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ (–∞–Ω–∞–ª–æ–≥ `ml.nn_set_device()`)
- **`model.get_device()`** - –ø–æ–ª—É—á–µ–Ω–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ (–∞–Ω–∞–ª–æ–≥ `ml.nn_get_device()`)

#### –°–≤–æ–π—Å—Ç–≤–∞

- **`model.layers[i]`** - –¥–æ—Å—Ç—É–ø –∫ —Å–ª–æ—é –ø–æ –∏–Ω–¥–µ–∫—Å—É

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
# –û–±—É—á–µ–Ω–∏–µ
loss_history = model.train(x_train, y_train, 10, 32, 0.001, "cross_entropy")

# –û–±—É—á–µ–Ω–∏–µ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–æ–º
loss_history = model.train(x_train, y_train, 10, 32, 0.001, 
                           "cross_entropy", "Adam", x_val, y_val)

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
model.save("my_model.nn")

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
model.device("metal")

# –î–æ—Å—Ç—É–ø –∫ —Å–ª–æ—è–º
first_layer = model.layers[0]
```

---

### Dataset

–î–∞—Ç–∞—Å–µ—Ç—ã –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é:

- **`dataset[i]`** - –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç `[features, target]` –¥–ª—è i-–≥–æ –æ–±—Ä–∞–∑—Ü–∞

**–ü—Ä–∏–º–µ—Ä—ã:**
```datacode
dataset = ml.load_mnist("train")
sample = dataset[0]  # [features_tensor, target_value]
features = sample[0]
target = sample[1]
```

---

## –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### –ü–æ–ª–Ω—ã–π –ø—Ä–∏–º–µ—Ä –æ–±—É—á–µ–Ω–∏—è MLP –Ω–∞ MNIST

```datacode
import ml

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
train_dataset = ml.load_mnist("train")
test_dataset = ml.load_mnist("test")

x_train = ml.dataset_features(train_dataset)  # [60000, 784]
y_train = ml.dataset_targets(train_dataset)   # [60000, 1]

x_test = ml.dataset_features(test_dataset)    # [10000, 784]
y_test = ml.dataset_targets(test_dataset)     # [10000, 1]

# –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
layer1 = ml.layer.linear(784, 128)
layer2 = ml.layer.relu()
layer3 = ml.layer.linear(128, 10)
model_seq = ml.sequential([layer1, layer2, layer3])
model = ml.neural_network(model_seq)

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
model.device("metal")  # –∏–ª–∏ "cuda" –¥–ª—è Linux/Windows

# –û–±—É—á–µ–Ω–∏–µ
loss_history = model.train(x_train, y_train, 
                           10, 64, 0.001, 
                           "cross_entropy", "Adam", x_test, y_test)

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
predictions = ml.nn_forward(model, x_test)

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
model.save("mnist_model.nn")
```

### –ü—Ä–∏–º–µ—Ä —Å early stopping

```datacode
import ml

# ... —Å–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö ...

# –û–±—É—á–µ–Ω–∏–µ —Å early stopping
history = model.train_sh(x_train, y_train, 50, 32, 0.001,
                         "cross_entropy", "Adam", "val_loss", 5, 0.0001, true,
                         x_val, y_val)

print("–û–±—É—á–µ–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –Ω–∞ —ç–ø–æ—Ö–µ:", history.stopped_epoch)
print("–õ—É—á—à–∞—è —ç–ø–æ—Ö–∞:", history.best_epoch)
print("–õ—É—á—à–∞—è –º–µ—Ç—Ä–∏–∫–∞:", history.best_metric)
```

### –ü—Ä–∏–º–µ—Ä —Ä–∞–±–æ—Ç—ã —Å —Ç–µ–Ω–∑–æ—Ä–∞–º–∏

```datacode
import ml

# –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ–Ω–∑–æ—Ä–æ–≤
a = ml.tensor([[1, 2], [3, 4]])
b = ml.tensor([[5, 6], [7, 8]])

# –û–ø–µ—Ä–∞—Ü–∏–∏
c = ml.add(a, b)        # –ü–æ—ç–ª–µ–º–µ–Ω—Ç–Ω–æ–µ —Å–ª–æ–∂–µ–Ω–∏–µ
d = ml.matmul(a, b)     # –ú–∞—Ç—Ä–∏—á–Ω–æ–µ —É–º–Ω–æ–∂–µ–Ω–∏–µ
e = ml.transpose(a)     # –¢—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ

# –°–≤–æ–π—Å—Ç–≤–∞ –∏ –º–µ—Ç–æ–¥—ã
shape = a.shape         # [2, 2]
data = a.data           # [1.0, 2.0, 3.0, 4.0]
max_idx = a.max_idx()   # [3]
sum_val = ml.sum(a)     # 10.0
mean_val = ml.mean(a)   # 2.5
```

### –ü—Ä–∏–º–µ—Ä –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏

```datacode
import ml

# –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
model = ml.linear_regression(3)  # 3 –ø—Ä–∏–∑–Ω–∞–∫–∞

# –û–±—É—á–µ–Ω–∏–µ
x_train = ml.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
y_train = ml.tensor([[6], [15], [24]])
loss_history = ml.lr_train(model, x_train, y_train, 100, 0.01)

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
x_test = ml.tensor([[2, 3, 4]])
prediction = ml.lr_predict(model, x_test)

# –û—Ü–µ–Ω–∫–∞
mse = ml.lr_evaluate(model, x_test, y_test)
```

---

## –°–≤—è–∑–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã

- [–°—Ö–µ–º–∞ –æ–±—É—á–µ–Ω–∏—è –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏](./training_flow.md) - –ø–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è
- [–§–æ—Ä–º–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π](./model_save_format.md) - –æ–ø–∏—Å–∞–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–∞ —Ñ–∞–π–ª–æ–≤ –º–æ–¥–µ–ª–µ–π
- [–í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏](./builtin_functions.md) - –¥—Ä—É–≥–∏–µ –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ DataCode
- [–ü—Ä–∏–º–µ—Ä—ã MNIST MLP](../../examples/ru/11-mnist-mlp/) - –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

---

**–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:** –î–∞–Ω–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∫–æ–¥–∞ DataCode. –í—Å–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω—ã –∏ —Ä–∞–±–æ—Ç–∞—é—Ç –≤ —Ç–µ–∫—É—â–µ–π –≤–µ—Ä—Å–∏–∏ —è–∑—ã–∫–∞.

